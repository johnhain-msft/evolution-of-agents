{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60db279a",
   "metadata": {},
   "source": [
    "# Evolution of agents - MCP - Postgress\n",
    "\n",
    "MCP (Model Context Protocol) is an open spec that standardizes how AI clients (agents, IDEs, chat apps) discover and call external tools and access resources. It uses a clientâ€“server model where servers expose capabilities (tools/functions, prompts, resources like files/DBs) over JSON-RPC transports (e.g., stdio, WebSocket). The goal is portability and safety: tools are reusable across different LLM runtimes with consistent schemas, auth, and streaming I/O, while remaining sandboxed. In practice, you run an MCP server for a service and any MCP-compatible client can list its capabilities and invoke them.\n",
    "<img src=\"./images/agent_actions.png\" alt=\"Agent with Actions\" style=\"max-height: 300px;\" />\n",
    "\n",
    "**Description:**\n",
    "This notebook explores how agents can interact with external MCP servers to discover and invoke tools, prompts, and resources. It demonstrates the client-server architecture for tool orchestration, focusing on portability, safety, and cross-runtime compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa7391a",
   "metadata": {},
   "source": [
    "## Postgres DB\n",
    "\n",
    "Use (Pagila)[https://github.com/devrimgunduz/pagila] to get postgress running.\n",
    "\n",
    "1. Clone the repository\n",
    "2. Use docker compose to get started `docker compose up`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b519ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference using Semantic Kernel\n",
    "from semantic_kernel import Kernel\n",
    "from setup import get_project_client, create_agent_chat_completions, test_agent\n",
    "from semantic_kernel.connectors.mcp import MCPStdioPlugin\n",
    "\n",
    "client = await get_project_client()\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "async with MCPStdioPlugin(\n",
    "    name=\"Postrgres\",\n",
    "    command=\"uvx\",\n",
    "    args=[\"postgres-mcp\", \"--access-mode=unrestricted\"],\n",
    "    description=\"MCP Stdio Plugin for Postgres\",\n",
    "    env={\n",
    "        \"DATABASE_URI\": \"postgres://postgres:123456@localhost:5432\"\n",
    "    },\n",
    "    version=\"1.0.0\",\n",
    ") as postgres_mpc:\n",
    "    kernel.add_plugin(postgres_mpc, plugin_name=\"postgres_mcp\")\n",
    "\n",
    "    agent = await create_agent_chat_completions(\n",
    "        agent_name=\"PGAgentWithMcp\",\n",
    "        agent_instructions=\"You are a helpful assistant. Use tools to solve user queries. Think deep. Perform analysis. You may need to make multiple tool calls.\",\n",
    "        client=client,\n",
    "        kernel=kernel,\n",
    "        plugins=[postgres_mpc],\n",
    "    )\n",
    "\n",
    "    thread = None\n",
    "    user_input = \"analyze the schema of the movie database (public schema) find top 5 interesting analytics insights from the movie data (like most popular actor) and generate a report using tables and emojis\"\n",
    "    thread = await test_agent(client, agent, user_input, thread)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
